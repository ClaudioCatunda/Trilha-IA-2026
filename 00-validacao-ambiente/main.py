import requests

def verificar_ia_local():
    print("ü§ñ Verificando integridade do setup no Catunda_SSD...")
    url = "http://localhost:11434/api/generate"
    payload = {
        "model": "llama3.2:1b",
        "prompt": "Responda apenas: Sistema Operacional de IA 2026 Online.",
        "stream": False
    }

    try:
        response = requests.post(url, json=payload)
        if response.status_code == 200:
            msg = response.json().get('response')
            print(f"‚úÖ SUCESSO! Resposta da IA: {msg}")
        else:
            print("‚ö†Ô∏è O Ollama respondeu, mas com erro. Verifique se o modelo foi baixado.")
    except Exception as e:
        print("‚ùå ERRO: O servidor Ollama n√£o foi encontrado.")
        print("üëâ Lembre-se de rodar 'ollama-ssd' em outra aba do terminal!")

if __name__ == "__main__":
    verificar_ia_local()